# SHAP: Explicando DecisÃµes de Machine Learning

**SHAP** (SHapley Additive exPlanations) Ã© uma tÃ©cnica de **explicabilidade de IA** baseada na teoria dos jogos que responde Ã  pergunta: **"Por que o modelo tomou essa decisÃ£o?"**

## ğŸ¯ O Problema que SHAP Resolve

Modelos de ML como Random Forest sÃ£o "caixas-pretas" â€” eles fazem previsÃµes precisas, mas nÃ£o dizem **por quÃª**. No seu caso:

```
Cliente X â†’ [Random Forest] â†’ 85% de risco âŒ Reprovado
                    â†‘
              Por quÃª 85%? ğŸ¤”
```

## ğŸ” Como SHAP Funciona

SHAP atribui um **valor de contribuiÃ§Ã£o** para cada feature, mostrando o quanto ela **aumentou** ou **diminuiu** a probabilidade de risco:

### Exemplo Real do Sistema:
```python
Cliente com 85% de risco de inadimplÃªncia:

Feature                    | Valor SHAP | InterpretaÃ§Ã£o
---------------------------|------------|--------------------------------
PAY_0 (atraso atual)       | +0.32      | Atraso de 2 meses â†’ aumenta muito o risco
LIMIT_BAL (limite)         | -0.08      | Limite alto de R$ 50k â†’ reduz o risco
PAY_AMT1 (pagamento)       | -0.05      | Pagou R$ 2k no Ãºltimo mÃªs â†’ reduz risco
AGE (idade)                | +0.02      | 23 anos â†’ aumenta levemente o risco
```

## ğŸ’¡ Por Que SHAP Ã© Usado Neste Sistema?

### 1ï¸âƒ£ **Conformidade Legal (Lei Geral de ProteÃ§Ã£o de Dados)**
```
âŒ "CrÃ©dito negado"  
âœ… "CrÃ©dito negado porque vocÃª tem 2 meses de atraso 
    e histÃ³rico de pagamento irregular"
```

### 2ï¸âƒ£ **GeraÃ§Ã£o de Prompts para o LLM**
No cÃ³digo (`explain.py`), SHAP Ã© usado para alimentar o Ollama:

```python
# 1. SHAP extrai os fatores
shap_values = compute_shap_single(pipeline, cliente)
fatores = extract_shap_factors(shap_values, top_k=5)

# 2. Fatores vÃ£o para o prompt do LLM
prompt = build_credit_prompt(
    decision="Reprovado",
    prob=0.85,
    factors=fatores  # â† AQUI entra o SHAP!
)

# 3. LLM gera explicaÃ§Ã£o humanizada
"Seu crÃ©dito foi negado principalmente devido ao atraso 
de 2 meses no pagamento. Recomendamos regularizar..."
```

### 3ï¸âƒ£ **PrecisÃ£o vs. GenÃ©rico**
```
Sem SHAP (LLM sozinho):
"Seu crÃ©dito foi negado por questÃµes de histÃ³rico financeiro"
                    â†‘ Vago e inÃºtil

Com SHAP + LLM:
"Os 2 fatores principais foram:
 1. Atraso de 2 meses (PAY_0) - impacto alto
 2. Limite baixo de R$ 5k - impacto mÃ©dio
 SugestÃ£o: Regularize os pagamentos em atraso..."
                    â†‘ EspecÃ­fico e acionÃ¡vel
```

## ğŸ› ï¸ Como Funciona no Pipeline

```
Cliente â†’ Random Forest â†’ Probabilidade 85%
                              â†“
                         [SHAP Explainer]
                              â†“
                    Top 5 features + valores
                              â†“
                      [Prompt Engineering]
                              â†“
                          Ollama LLM
                              â†“
                   ExplicaÃ§Ã£o em portuguÃªs
```

### Fluxo Detalhado:

1. **Random Forest** gera probabilidade de risco (ex: 85%)
2. **SHAP Explainer** calcula contribuiÃ§Ã£o de cada feature
3. **Top K Features** sÃ£o extraÃ­das (5 mais relevantes)
4. **Prompt Builder** monta contexto estruturado para LLM
5. **Ollama (qwen2.5:0.5b)** gera explicaÃ§Ã£o em linguagem natural
6. **Cliente** recebe explicaÃ§Ã£o personalizada e acionÃ¡vel

## ğŸ“Š Visualizando SHAP

O sistema gera uma tabela com os principais fatores:

| Feature | Valor | Impacto SHAP | DireÃ§Ã£o |
|---------|-------|--------------|---------|
| PAY_0   | 2 meses | +0.32 | ğŸ”´ Aumenta risco |
| LIMIT_BAL | R$ 50k | -0.08 | ğŸŸ¢ Reduz risco |
| PAY_AMT1 | R$ 2k | -0.05 | ğŸŸ¢ Reduz risco |
| BILL_AMT1 | R$ 15k | +0.03 | ğŸ”´ Aumenta risco |
| PAY_2 | 1 mÃªs | +0.02 | ğŸ”´ Aumenta risco |

## ğŸ“ Teoria: Shapley Values (Nobel de Economia 2012)

SHAP usa a teoria dos **Shapley Values**, que responde:

> "Se cada feature fosse um 'jogador' contribuindo para a decisÃ£o, qual seria a contribuiÃ§Ã£o justa de cada uma?"

Ã‰ como dividir um prÃªmio de equipe considerando a contribuiÃ§Ã£o individual de cada membro.

### Propriedades MatemÃ¡ticas:

1. **Aditividade**: Soma dos valores SHAP = diferenÃ§a entre prediÃ§Ã£o e valor base
2. **ConsistÃªncia**: Se uma feature contribui mais, seu valor SHAP Ã© maior
3. **Simetria**: Features com mesma contribuiÃ§Ã£o tÃªm mesmo valor SHAP
4. **Dummy**: Features irrelevantes tÃªm valor SHAP = 0

## âœ… Vantagens no Caso de Uso de CrÃ©dito

1. **ConfianÃ§a**: Clientes entendem por que foram reprovados
2. **Auditoria**: VocÃª pode provar que o modelo nÃ£o Ã© discriminatÃ³rio
3. **Melhoria**: Clientes sabem o que fazer para melhorar (ex: "pague em dia por 3 meses")
4. **Debugar**: Se o modelo rejeitar um bom cliente, vocÃª vÃª quais features erraram
5. **RegulatÃ³rio**: Atende exigÃªncias de transparÃªncia (LGPD, GDPR)
6. **NegÃ³cio**: Analistas podem questionar decisÃµes e ajustar thresholds

## ğŸ“ Exemplo PrÃ¡tico de SaÃ­da

### Entrada (Cliente):
```python
{
  "LIMIT_BAL": 50000,
  "AGE": 23,
  "PAY_0": 2,  # 2 meses de atraso
  "PAY_AMT1": 2000,
  "BILL_AMT1": 15000
}
```

### SHAP (AnÃ¡lise TÃ©cnica):
```
PAY_0 = 2 meses â†’ SHAP: +0.32 (forte impacto negativo)
LIMIT_BAL = R$ 50k â†’ SHAP: -0.08 (impacto positivo mÃ©dio)
PAY_AMT1 = R$ 2k â†’ SHAP: -0.05 (impacto positivo baixo)
```

### LLM (ExplicaÃ§Ã£o Humanizada):
```
ğŸ”´ CrÃ©dito Reprovado (85% de risco)

Principais motivos:
1. VocÃª possui 2 meses de atraso nos pagamentos (PAY_0)
   - Este Ã© o fator mais crÃ­tico na sua anÃ¡lise

2. Seu limite atual de R$ 50.000 Ã© positivo, mas nÃ£o 
   compensa o histÃ³rico de atrasos

3. Pagamento recente de R$ 2.000 demonstra esforÃ§o, 
   porÃ©m insuficiente para reverter o risco

ğŸ’¡ RecomendaÃ§Ãµes:
- Regularize os pagamentos em atraso imediatamente
- Mantenha pagamentos pontuais por 3-6 meses
- Considere renegociar dÃ­vidas pendentes
```

## ğŸš€ Resumo

**SHAP** transforma o modelo de uma caixa-preta em um **sistema transparente e auditÃ¡vel**, fornecendo a base tÃ©cnica que o **LLM (Ollama) transforma em linguagem humana** para os clientes.

```
Modelo ML    â†’  SHAP        â†’  LLM           â†’  Cliente
"85% risco"  â†’  "PAY_0=+0.32"  â†’  "2 meses de atraso"  â†’  "Entendi!"
```

Ã‰ a combinaÃ§Ã£o perfeita: **precisÃ£o tÃ©cnica** (SHAP) + **comunicaÃ§Ã£o humana** (LLM) ğŸ¯

## ğŸ”— ReferÃªncias

- [Paper Original SHAP](https://arxiv.org/abs/1705.07874)
- [DocumentaÃ§Ã£o SHAP](https://shap.readthedocs.io/)
- [Shapley Values (Teoria dos Jogos)](https://en.wikipedia.org/wiki/Shapley_value)
- [Interpretable ML Book](https://christophm.github.io/interpretable-ml-book/)

## ğŸ“š Arquivos Relacionados no Projeto

- `src/explain.py` - ImplementaÃ§Ã£o do SHAP Explainer
- `src/prompts.py` - ConstruÃ§Ã£o de prompts com dados SHAP
- `src/llm.py` - IntegraÃ§Ã£o com Ollama para geraÃ§Ã£o de texto
- `src/app.py` - Interface Streamlit com visualizaÃ§Ã£o SHAP
