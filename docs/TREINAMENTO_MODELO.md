# ğŸ“ Guia Completo: Treinamento do Modelo de Risco de CrÃ©dito

Este documento explica detalhadamente o processo de treinamento do modelo de Machine Learning utilizado no sistema de anÃ¡lise de risco de crÃ©dito.

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#-visÃ£o-geral)
2. [PreparaÃ§Ã£o dos Dados](#-preparaÃ§Ã£o-dos-dados)
3. [Pipeline de PrÃ©-processamento](#-pipeline-de-prÃ©-processamento)
4. [Algoritmo e HiperparÃ¢metros](#-algoritmo-e-hiperparÃ¢metros)
5. [Processo de Treinamento](#-processo-de-treinamento)
6. [AvaliaÃ§Ã£o do Modelo](#-avaliaÃ§Ã£o-do-modelo)
7. [SerializaÃ§Ã£o e Deploy](#-serializaÃ§Ã£o-e-deploy)
8. [Como Executar](#-como-executar)
9. [OtimizaÃ§Ã£o e Melhorias](#-otimizaÃ§Ã£o-e-melhorias)

---

## ğŸ¯ VisÃ£o Geral

### Objetivo
Treinar um modelo de **classificaÃ§Ã£o binÃ¡ria** para prever se um cliente de cartÃ£o de crÃ©dito irÃ¡ inadimplir no prÃ³ximo mÃªs.

### CaracterÃ­sticas do Modelo
- **Algoritmo**: Random Forest Classifier
- **Framework**: Scikit-learn 1.3+
- **Dataset**: UCI Credit Card Default (30.000 clientes)
- **Target**: `default.payment.next.month` (0 = Paga, 1 = Inadimplente)
- **Features**: 23 variÃ¡veis (demogrÃ¡ficas, limite, histÃ³rico de pagamento)
- **Split**: 80% treino (24.000) / 20% teste (6.000)

### Arquivo Principal
```
src/train_model.py
```

---

## ğŸ“Š PreparaÃ§Ã£o dos Dados

### 1ï¸âƒ£ **Carregamento**
```python
df = pd.read_csv("../data/UCI_Credit_Card.csv")
# Shape: (30000, 25) - 30 mil clientes, 25 colunas
```

### 2ï¸âƒ£ **Limpeza de Dados**
```python
# Corrigir valores invÃ¡lidos em EDUCATION
# 0, 5, 6 sÃ£o valores nÃ£o documentados â†’ agrupados em "outros" (4)
df.loc[df.EDUCATION.isin([0, 5, 6]), 'EDUCATION'] = 4

# Corrigir valores invÃ¡lidos em MARRIAGE
# 0 nÃ£o estÃ¡ na documentaÃ§Ã£o â†’ agrupado em "outros" (3)
df.loc[df.MARRIAGE == 0, 'MARRIAGE'] = 3
```

**Motivo**: O dataset original contÃ©m valores nÃ£o documentados que podem confundir o modelo.

### 3ï¸âƒ£ **SeparaÃ§Ã£o de Features e Target**
```python
# Remover colunas nÃ£o preditivas
X = df.drop(columns=["default.payment.next.month", "ID"], errors="ignore")
y = df["default.payment.next.month"]

# X: 23 features numÃ©ricas
# y: 0 (Paga) = 23,364 | 1 (Inadimplente) = 6,636
```

### 4ï¸âƒ£ **Split Estratificado**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 20% para teste
    random_state=42,    # Reprodutibilidade
    stratify=y          # Manter proporÃ§Ã£o de classes
)
```

**Stratify**: Garante que a proporÃ§Ã£o 78% Paga / 22% Inadimplente seja mantida em ambos os conjuntos.

---

## ğŸ—ï¸ Pipeline de PrÃ©-processamento

### Por que usar Pipeline?
1. **Evita data leakage**: TransformaÃ§Ãµes sÃ£o aplicadas apenas nos dados de treino
2. **Reprodutibilidade**: Mesmo prÃ©-processamento em produÃ§Ã£o
3. **SerializaÃ§Ã£o fÃ¡cil**: Todo o fluxo Ã© salvo em um Ãºnico arquivo `.pkl`

### Estrutura do Pipeline

```python
Pipeline([
    ('preprocessor', ColumnTransformer),  # Etapa 1: PrÃ©-processamento
    ('classifier', RandomForestClassifier) # Etapa 2: Modelo
])
```

### PrÃ©-processador
```python
preprocessor = ColumnTransformer(
    transformers=[
        ('scaler', StandardScaler(), slice(None))  # Escala todas as features
    ],
    remainder='passthrough'
)
```

**StandardScaler**: Padroniza features para mÃ©dia=0 e desvio=1.

**Por quÃª escalar?**
- Melhora convergÃªncia de algoritmos
- Evita que features com valores grandes dominem
- Exemplo: `LIMIT_BAL` (0-1.000.000) vs `AGE` (21-79)

**ApÃ³s escalonamento:**
```
LIMIT_BAL: 50000 â†’ -0.23
AGE: 35 â†’ 0.45
```

---

## ğŸŒ² Algoritmo e HiperparÃ¢metros

### Por que Random Forest?

| Vantagem | DescriÃ§Ã£o |
|----------|-----------|
| âœ… **Robusto** | Lida bem com outliers e dados ruidosos |
| âœ… **Feature Importance** | Identifica variÃ¡veis mais importantes |
| âœ… **NÃ£o-linear** | Captura relaÃ§Ãµes complexas sem engenharia manual |
| âœ… **Pouco overfitting** | Ensemble de Ã¡rvores reduz variÃ¢ncia |
| âœ… **InterpretÃ¡vel** | SHAP consegue explicar decisÃµes |

### HiperparÃ¢metros Configurados

```python
RandomForestClassifier(
    n_estimators=100,           # NÃºmero de Ã¡rvores na floresta
    max_depth=15,               # Profundidade mÃ¡xima de cada Ã¡rvore
    min_samples_split=10,       # MÃ­nimo de amostras para dividir nÃ³
    min_samples_leaf=5,         # MÃ­nimo de amostras em folha
    random_state=42,            # Seed para reprodutibilidade
    n_jobs=-1,                  # Usar todos os CPUs disponÃ­veis
    class_weight='balanced'     # Ajuste para desbalanceamento de classes
)
```

### ğŸ“Š ExplicaÃ§Ã£o dos HiperparÃ¢metros

#### 1. **n_estimators=100**
- NÃºmero de Ã¡rvores de decisÃ£o no ensemble
- Mais Ã¡rvores â†’ Melhor performance (atÃ© certo ponto)
- 100 Ã© um bom equilÃ­brio entre performance e tempo

#### 2. **max_depth=15**
- Limita profundidade das Ã¡rvores
- Evita overfitting (Ã¡rvores muito especÃ­ficas)
- 15 nÃ­veis Ã© suficiente para capturar padrÃµes complexos

#### 3. **min_samples_split=10**
- NÃºmero mÃ­nimo de amostras para dividir um nÃ³
- Valores maiores â†’ Ãrvores mais generalizadas
- Reduz overfitting em nÃ³s com poucos exemplos

#### 4. **min_samples_leaf=5**
- NÃºmero mÃ­nimo de amostras em cada folha
- Evita folhas com 1-2 exemplos (ruÃ­do)
- Melhora generalizaÃ§Ã£o

#### 5. **class_weight='balanced'**
- **CRÃTICO para dados desbalanceados!**
- Dataset: 78% Paga / 22% Inadimplente
- Ajusta pesos automaticamente: `n_samples / (n_classes * np.bincount(y))`

**Sem balanceamento:**
```
Modelo tende a prever sempre "Paga" (classe majoritÃ¡ria)
AcurÃ¡cia: 78% (mas nÃ£o detecta inadimplentes!)
```

**Com balanceamento:**
```
Penaliza erros na classe minoritÃ¡ria (inadimplentes)
ForÃ§a o modelo a aprender padrÃµes de ambas as classes
```

---

## ğŸš€ Processo de Treinamento

### Fluxo Completo

```python
def main():
    # 1. Carregar e preparar dados
    X_train, X_test, y_train, y_test = load_and_prepare_data()
    
    # 2. Criar pipeline
    pipeline = create_pipeline()
    
    # 3. Treinar modelo
    pipeline.fit(X_train, y_train)
    
    # 4. Avaliar no conjunto de teste
    evaluate_model(pipeline, X_test, y_test)
    
    # 5. Salvar modelo treinado
    save_model(pipeline, "models/modelo_credito.pkl")
```

### Detalhamento das Etapas

#### **Etapa 1: Carregamento**
```
ğŸ“Š Carregando dados...
âœ… Dados carregados: 30000 linhas, 25 colunas
ğŸ§¹ Limpando dados...
âœ… Features: 23
âœ… Target distribuiÃ§Ã£o: {0: 23364, 1: 6636}
âœ… Train set: 24000 amostras
âœ… Test set: 6000 amostras
```

#### **Etapa 2: Pipeline**
```
ğŸ—ï¸ Criando pipeline...
âœ… Pipeline criado!
```

#### **Etapa 3: Treinamento**
```
ğŸš€ Iniciando treinamento...
[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.
[Parallel(n_jobs=-1)]: Done  42 tasks | elapsed:   12.3s
[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   28.7s finished
âœ… Treinamento concluÃ­do!
```

**Tempo de treinamento**: ~30 segundos (varia por hardware)

#### **Etapa 4: AvaliaÃ§Ã£o**
```
ğŸ“ˆ Avaliando modelo...

ğŸ“Š RELATÃ“RIO DE CLASSIFICAÃ‡ÃƒO:
              precision    recall  f1-score   support

        Paga       0.87      0.87      0.87      4673
     Default       0.54      0.54      0.54      1327

    accuracy                           0.80      6000
   macro avg       0.71      0.71      0.71      6000
weighted avg       0.80      0.80      0.80      6000

ğŸ“Š MATRIZ DE CONFUSÃƒO:
[[4073  600]
 [ 616  711]]

ğŸ“Š ROC-AUC Score: 0.7707
âœ… Matriz de confusÃ£o salva em '../reports/confusion_matrix.png'
âœ… Curva ROC salva em '../reports/roc_curve.png'
```

---

## ğŸ“ˆ AvaliaÃ§Ã£o do Modelo

### MÃ©tricas Principais

#### 1ï¸âƒ£ **AcurÃ¡cia: 80%**
```
Acertos Totais / Total de PrediÃ§Ãµes
(4073 + 711) / 6000 = 0.80
```
âœ… **InterpretaÃ§Ã£o**: Acerta 8 em cada 10 prediÃ§Ãµes

#### 2ï¸âƒ£ **Precision (PrecisÃ£o)**

**Classe "Paga" (0): 87%**
```
Verdadeiros Negativos / (Verdadeiros Negativos + Falsos Negativos)
4073 / (4073 + 600) = 0.87
```
âœ… Quando diz que vai pagar, estÃ¡ certo 87% das vezes

**Classe "Inadimplente" (1): 54%**
```
Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos)
711 / (711 + 616) = 0.54
```
âš ï¸ Quando diz que vai dar default, estÃ¡ certo apenas 54% das vezes

#### 3ï¸âƒ£ **Recall (Sensibilidade)**

**Classe "Paga" (0): 87%**
```
Verdadeiros Negativos / Total Real de Pagantes
4073 / 4673 = 0.87
```
âœ… Detecta 87% de todos os bons pagadores

**Classe "Inadimplente" (1): 54%**
```
Verdadeiros Positivos / Total Real de Inadimplentes
711 / 1327 = 0.54
```
âš ï¸ Detecta apenas 54% dos inadimplentes (46% escapam!)

#### 4ï¸âƒ£ **ROC-AUC: 0.7707**
```
Ãrea sob a curva ROC
```
âœ… **InterpretaÃ§Ã£o**: 
- Score > 0.7 Ã© considerado **bom** para problemas de crÃ©dito
- 77% de chance de ranquear um inadimplente com score maior que um pagador
- Quanto mais prÃ³ximo de 1.0, melhor

### Matriz de ConfusÃ£o Explicada

```
                  PREDITO: Paga    PREDITO: Inadimplente
REAL: Paga            4,073 (TN)         600 (FP)
REAL: Inadimplente      616 (FN)         711 (TP)
```

| Quadrante | Valor | Nome | Impacto de NegÃ³cio |
|-----------|-------|------|-------------------|
| **TN** | 4,073 | Verdadeiro Negativo | âœ… Aprovados corretamente â†’ Lucro |
| **FP** | 600 | Falso Positivo | âš ï¸ Bons clientes rejeitados â†’ Oportunidade perdida |
| **FN** | 616 | Falso Negativo | âŒ Maus clientes aprovados â†’ PrejuÃ­zo! |
| **TP** | 711 | Verdadeiro Positivo | âœ… Maus clientes rejeitados â†’ PrejuÃ­zo evitado |

### ğŸ’° SimulaÃ§Ã£o de Impacto Financeiro

**Premissas:**
- Lucro por cliente aprovado: R$ 100
- PrejuÃ­zo por inadimplente: R$ 1.000

**Resultado com threshold 0.5:**
```
Aprovados: 4,073 + 616 = 4,689
Lucro: 4,073 Ã— R$ 100 = R$ 407,300
PrejuÃ­zo: 616 Ã— R$ 1,000 = R$ 616,000
RESULTADO: -R$ 208,700 (prejuÃ­zo!)
```

**Ajustando threshold para 0.3 (mais agressivo):**
```
Aprovados: ~5,200
Inadimplentes aprovados: ~800
Lucro: 4,400 Ã— R$ 100 = R$ 440,000
PrejuÃ­zo: 800 Ã— R$ 1,000 = R$ 800,000
RESULTADO: -R$ 360,000 (pior!)
```

**Ajustando threshold para 0.7 (mais conservador):**
```
Aprovados: ~3,800
Inadimplentes aprovados: ~350
Lucro: 3,450 Ã— R$ 100 = R$ 345,000
PrejuÃ­zo: 350 Ã— R$ 1,000 = R$ 350,000
RESULTADO: -R$ 5,000 (quase break-even!)
```

ğŸ¯ **ConclusÃ£o**: O threshold ideal depende da estratÃ©gia de negÃ³cio e deve ser ajustado no Streamlit!

---

## ğŸ’¾ SerializaÃ§Ã£o e Deploy

### Salvando o Modelo

```python
import joblib

# Salvar pipeline completo (preprocessador + modelo)
joblib.dump(pipeline, "../models/modelo_credito.pkl")
```

**O que Ã© salvo:**
- âœ… Pipeline completo (preprocessador + Random Forest)
- âœ… HiperparÃ¢metros configurados
- âœ… Ãrvores treinadas (100 Ã¡rvores com seus splits)
- âœ… Scaler com mÃ©dia/desvio calculados no treino

**Tamanho do arquivo**: ~2-5 MB (depende das Ã¡rvores)

### Carregando em ProduÃ§Ã£o

```python
# Em app.py
pipeline = joblib.load("models/modelo_credito.pkl")

# Fazer prediÃ§Ã£o
probs = pipeline.predict_proba(X_new)[:, 1]
```

**Vantagens:**
- âœ… Mesmas transformaÃ§Ãµes aplicadas automaticamente
- âœ… Nenhum prÃ©-processamento manual necessÃ¡rio
- âœ… Garantia de reprodutibilidade

---

## ğŸš€ Como Executar

### PrÃ©-requisitos
```bash
pip install -r requirements.txt
```

### Treinamento Local

```bash
# Navegar para o diretÃ³rio src
cd src

# Executar script de treinamento
python train_model.py
```

### SaÃ­da Esperada
```
============================================================
ğŸ¯ TREINAMENTO DO MODELO DE RISCO DE CRÃ‰DITO
============================================================
ğŸ“Š Carregando dados...
âœ… Dados carregados: 30000 linhas, 25 colunas
ğŸ§¹ Limpando dados...
âœ… Features: 23
âœ… Target distribuiÃ§Ã£o: {0: 23364, 1: 6636}
âœ… Train set: 24000 amostras
âœ… Test set: 6000 amostras
ğŸ—ï¸ Criando pipeline...
âœ… Pipeline criado!

ğŸš€ Iniciando treinamento...
âœ… Treinamento concluÃ­do!

ğŸ“ˆ Avaliando modelo...

ğŸ“Š RELATÃ“RIO DE CLASSIFICAÃ‡ÃƒO:
              precision    recall  f1-score   support

        Paga       0.87      0.87      0.87      4673
     Default       0.54      0.54      0.54      1327

    accuracy                           0.80      6000
   macro avg       0.71      0.71      0.71      6000
weighted avg       0.80      0.80      0.80      6000

ğŸ“Š MATRIZ DE CONFUSÃƒO:
[[4073  600]
 [ 616  711]]

ğŸ“Š ROC-AUC Score: 0.7707
âœ… Matriz de confusÃ£o salva em '../reports/confusion_matrix.png'
âœ… Curva ROC salva em '../reports/roc_curve.png'

ğŸ’¾ Salvando modelo em '../models/modelo_credito.pkl'...
âœ… Modelo salvo com sucesso!
ğŸ“ RelatÃ³rio detalhado disponÃ­vel em '../reports/MODEL_REPORT.md'

============================================================
âœ… PROCESSO CONCLUÃDO COM SUCESSO!
============================================================
ğŸ“Š ROC-AUC Score: 0.7707
ğŸ’¾ Modelo salvo: models/modelo_credito.pkl
ğŸ“ˆ VisualizaÃ§Ãµes salvas: reports/confusion_matrix.png, reports/roc_curve.png
ğŸ“ RelatÃ³rio completo: reports/MODEL_REPORT.md

ğŸš€ Agora vocÃª pode executar o Streamlit com:
   cd src && streamlit run app.py
============================================================
```

### Arquivos Gerados

```
models/
â””â”€â”€ modelo_credito.pkl          # Pipeline treinado (~2-5 MB)

reports/
â”œâ”€â”€ confusion_matrix.png        # VisualizaÃ§Ã£o da matriz de confusÃ£o
â”œâ”€â”€ roc_curve.png               # Curva ROC
â””â”€â”€ MODEL_REPORT.md             # RelatÃ³rio tÃ©cnico detalhado
```

---

## ğŸ”§ OtimizaÃ§Ã£o e Melhorias

### Melhorias Implementadas Neste Fork

#### 1ï¸âƒ£ **Class Weight Balancing**
```python
class_weight='balanced'
```
âœ… Melhora detecÃ§Ã£o de inadimplentes (classe minoritÃ¡ria)

#### 2ï¸âƒ£ **RegularizaÃ§Ã£o das Ãrvores**
```python
max_depth=15,
min_samples_split=10,
min_samples_leaf=5
```
âœ… Evita overfitting mantendo boa capacidade preditiva

#### 3ï¸âƒ£ **Pipeline Completo**
```python
Pipeline([('preprocessor', ...), ('classifier', ...)])
```
âœ… Garante reprodutibilidade em produÃ§Ã£o

### PossÃ­veis Melhorias Futuras

#### 1ï¸âƒ£ **Grid Search para OtimizaÃ§Ã£o**
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'classifier__n_estimators': [100, 200, 300],
    'classifier__max_depth': [10, 15, 20],
    'classifier__min_samples_split': [5, 10, 15]
}

grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc')
grid_search.fit(X_train, y_train)
```

#### 2ï¸âƒ£ **Feature Engineering AvanÃ§ado**
```python
# Criar features derivadas
df['payment_consistency'] = df[['PAY_0', 'PAY_2', 'PAY_3']].std(axis=1)
df['credit_utilization'] = df['BILL_AMT1'] / df['LIMIT_BAL']
df['payment_ratio'] = df['PAY_AMT1'] / df['BILL_AMT1']
```

#### 3ï¸âƒ£ **Algoritmos Alternativos**
```python
# XGBoost (geralmente melhor que Random Forest)
from xgboost import XGBClassifier

model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    scale_pos_weight=3.5  # Ajuste para desbalanceamento
)
```

#### 4ï¸âƒ£ **ValidaÃ§Ã£o Cruzada**
```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')
print(f"ROC-AUC mÃ©dio: {scores.mean():.4f} (+/- {scores.std():.4f})")
```

#### 5ï¸âƒ£ **Threshold Optimization**
```python
from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)

# Encontrar threshold que maximiza F1-Score
f1_scores = 2 * (precisions * recalls) / (precisions + recalls)
best_threshold = thresholds[np.argmax(f1_scores)]
```

#### 6ï¸âƒ£ **SMOTE para Balanceamento**
```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
```

---

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o Relacionada
- ğŸ“„ [`SHAP_EXPLICACAO.md`](../SHAP_EXPLICACAO.md) - ExplicaÃ§Ã£o sobre interpretabilidade
- ğŸ“„ [`MODEL_REPORT.md`](../reports/MODEL_REPORT.md) - RelatÃ³rio tÃ©cnico detalhado
- ğŸ“„ [`QUICKSTART.md`](../QUICKSTART.md) - Guia rÃ¡pido de execuÃ§Ã£o
- ğŸ“„ [`DOCKER.md`](./DOCKER.md) - Deploy com Docker

### Links Ãšteis
- [Scikit-learn Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- [Understanding ROC-AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)
- [Handling Imbalanced Data](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)
- [UCI Credit Card Dataset](https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset)

---

## ğŸ“ Resumo

### O que o Processo de Treinamento Faz:

1. âœ… **Carrega** o dataset de 30 mil clientes
2. âœ… **Limpa** valores invÃ¡lidos em EDUCATION e MARRIAGE
3. âœ… **Separa** em 80% treino / 20% teste (estratificado)
4. âœ… **Cria pipeline** com StandardScaler + Random Forest
5. âœ… **Treina** 100 Ã¡rvores de decisÃ£o com class_weight='balanced'
6. âœ… **Avalia** com mÃºltiplas mÃ©tricas (Accuracy, Precision, Recall, ROC-AUC)
7. âœ… **Gera visualizaÃ§Ãµes** (matriz de confusÃ£o, curva ROC)
8. âœ… **Salva** pipeline completo em `models/modelo_credito.pkl`

### MÃ©tricas Atingidas:
- ğŸ“Š **AcurÃ¡cia**: 80%
- ğŸ“Š **ROC-AUC**: 0.7707
- ğŸ“Š **Precision (Inadimplente)**: 54%
- ğŸ“Š **Recall (Inadimplente)**: 54%

### PrÃ³ximos Passos:
1. Executar `python train_model.py` para treinar
2. Usar `streamlit run app.py` para testar o modelo
3. Ajustar threshold no Streamlit para otimizar lucro
4. Considerar melhorias (Grid Search, XGBoost, Feature Engineering)

---

<div align="center">

**ğŸ¯ Modelo treinado e pronto para produÃ§Ã£o! ğŸš€**

Para mais informaÃ§Ãµes, consulte [`MODEL_REPORT.md`](../reports/MODEL_REPORT.md)

</div>
